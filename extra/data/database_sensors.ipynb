{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcd62ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a085269a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fetch data from Dati Lombardia API\n",
    "def fetch_data_from_api(api_url):\n",
    "    response = requests.get(api_url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"API request failed with status code {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a702265d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Connect to PostgreSQL database\n",
    "def connect_to_postgres():\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\",       \n",
    "        database=\"lombardia_air_quality\", \n",
    "        user=\"airdata_user\",   \n",
    "        password=\"user\" \n",
    "    )\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b392b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create table if it doesn't exist\n",
    "def create_table_if_not_exists(conn, table_name, data_sample):\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Create schema SQL statement based on the data structure\n",
    "    columns = []\n",
    "    for key, value in data_sample.items():\n",
    "        column_type = \"TEXT\"  # Default type\n",
    "        \n",
    "        # Try to infer the data type\n",
    "        if isinstance(value, int):\n",
    "            column_type = \"INTEGER\"\n",
    "        elif isinstance(value, float):\n",
    "            column_type = \"NUMERIC\"\n",
    "        elif isinstance(value, bool):\n",
    "            column_type = \"BOOLEAN\"\n",
    "        elif isinstance(value, dict):\n",
    "            column_type = \"JSONB\"  # Use JSONB for nested structures\n",
    "        # Special case for timestamp fields\n",
    "        elif key == \"datastart\" or key == \"datastop\":\n",
    "            column_type = \"TIMESTAMP\"\n",
    "\n",
    "        columns.append(f\"\\\"{key}\\\" {column_type}\")\n",
    "\n",
    "    create_table_sql = f\"\"\"\n",
    "    DROP TABLE IF EXISTS {table_name};\n",
    "    CREATE TABLE {table_name} (\n",
    "        {', '.join(columns)},\n",
    "        PRIMARY KEY (\"idsensore\")\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.execute(create_table_sql)\n",
    "    conn.commit()\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af08941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Insert data into table\n",
    "def insert_data(conn, table_name, data_list):\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    if not data_list:\n",
    "        print(\"No data to insert\")\n",
    "        return\n",
    "    \n",
    "    # Get column names from the first data item\n",
    "    columns = list(data_list[0].keys())\n",
    "    \n",
    "    # Prepare values for insertion\n",
    "    values = [[item.get(col) for col in columns] for item in data_list]\n",
    "    \n",
    "    # Create the SQL query\n",
    "    insert_query = f\"\"\"\n",
    "    INSERT INTO {table_name} ({', '.join([f'\"{col}\"' for col in columns])})\n",
    "    VALUES %s\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query with all values\n",
    "    execute_values(cursor, insert_query, values)\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"Inserted {len(data_list)} records into {table_name}\")\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9060bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API URL\n",
    "api_url = \"https://www.dati.lombardia.it/resource/ib47-atvt.json\"\n",
    "\n",
    "# Define the table name for your data\n",
    "table_name = \"sensors\"\n",
    "\n",
    "try:\n",
    "    # Fetch data from API\n",
    "    print(\"Fetching data from API...\")\n",
    "    raw_data = fetch_data_from_api(api_url)\n",
    "    \n",
    "    # Debug: Inspect the data structure\n",
    "    print(\"Sample data item structure:\")\n",
    "    if raw_data:\n",
    "        print(json.dumps(raw_data[0], indent=2))\n",
    "    \n",
    "    # Connect to PostgreSQL\n",
    "    print(\"Connecting to PostgreSQL...\")\n",
    "    conn = connect_to_postgres()\n",
    "    \n",
    "    # Create table if it doesn't exist (using actual data to infer schema)\n",
    "    print(\"Creating table if it doesn't exist...\")\n",
    "    if processed_data:\n",
    "        create_table_if_not_exists(conn, table_name, processed_data[0])\n",
    "    \n",
    "    # Insert data into table\n",
    "    print(\"Inserting data into table...\")\n",
    "    insert_data(conn, table_name, processed_data)\n",
    "    \n",
    "    # Close connection\n",
    "    conn.close()\n",
    "    print(\"Process completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se4g",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

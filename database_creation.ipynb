{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a51b5053",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/se4g/lib/python3.13/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import psycopg2\n",
    "from psycopg2.extras import execute_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf02176d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Fetch data from Dati Lombardia API\n",
    "def fetch_data_from_api(api_url):\n",
    "    response = requests.get(api_url)\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        raise Exception(f\"API request failed with status code {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cc73d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Process API data and filter out problematic columns\n",
    "def process_api_data(data_list):\n",
    "    processed_data = []\n",
    "    \n",
    "    # List of columns to exclude\n",
    "    columns_to_exclude = [\":@computed_region_6hky_swhk\"]\n",
    "    \n",
    "    for item in data_list:\n",
    "        processed_item = {}\n",
    "        \n",
    "        # Copy only the desired fields, skipping problematic ones\n",
    "        for key, value in item.items():\n",
    "            # Skip excluded columns\n",
    "            if key in columns_to_exclude:\n",
    "                continue\n",
    "                \n",
    "            # Handle nested dictionaries by converting to JSON strings\n",
    "            if isinstance(value, dict):\n",
    "                processed_item[key] = json.dumps(value)\n",
    "            else:\n",
    "                processed_item[key] = value\n",
    "                \n",
    "        processed_data.append(processed_item)\n",
    "        \n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07ed4c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Connect to PostgreSQL database\n",
    "def connect_to_postgres():\n",
    "    conn = psycopg2.connect(\n",
    "        host=\"localhost\",        # Update with your database host\n",
    "        database=\"lombardia_air_quality\", # Update with your database name\n",
    "        user=\"postgres\",    # Update with your username\n",
    "        password=\"Milano\" # Update with your password\n",
    "    )\n",
    "    return conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dcef08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Create table if it doesn't exist\n",
    "def create_table_if_not_exists(conn, table_name, data_sample):\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Create schema SQL statement based on the data structure\n",
    "    columns = []\n",
    "    for key, value in data_sample.items():\n",
    "        column_type = \"TEXT\"  # Default type\n",
    "        \n",
    "        # Try to infer the data type\n",
    "        if isinstance(value, int):\n",
    "            column_type = \"INTEGER\"\n",
    "        elif isinstance(value, float):\n",
    "            column_type = \"NUMERIC\"\n",
    "        elif isinstance(value, bool):\n",
    "            column_type = \"BOOLEAN\"\n",
    "        elif isinstance(value, dict):\n",
    "            column_type = \"JSONB\"  # Use JSONB for nested structures\n",
    "        # Special case for timestamp fields\n",
    "        elif key == \"datastart\" or key == \"datastop\":\n",
    "            column_type = \"TIMESTAMP\"\n",
    "\n",
    "        columns.append(f\"\\\"{key}\\\" {column_type}\")\n",
    "\n",
    "    create_table_sql = f\"\"\"\n",
    "    DROP TABLE IF EXISTS {table_name};\n",
    "    CREATE TABLE {table_name} (\n",
    "        id SERIAL PRIMARY KEY,\n",
    "        {', '.join(columns)},\n",
    "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    "    );\n",
    "    \"\"\"\n",
    "    \n",
    "    cursor.execute(create_table_sql)\n",
    "    conn.commit()\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e52c0199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Insert data into table\n",
    "def insert_data(conn, table_name, data_list):\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    if not data_list:\n",
    "        print(\"No data to insert\")\n",
    "        return\n",
    "    \n",
    "    # Get column names from the first data item\n",
    "    columns = list(data_list[0].keys())\n",
    "    \n",
    "    # Prepare values for insertion\n",
    "    values = [[item.get(col) for col in columns] for item in data_list]\n",
    "    \n",
    "    # Create the SQL query\n",
    "    insert_query = f\"\"\"\n",
    "    INSERT INTO {table_name} ({', '.join([f'\"{col}\"' for col in columns])})\n",
    "    VALUES %s\n",
    "    \"\"\"\n",
    "    \n",
    "    # Execute the query with all values\n",
    "    execute_values(cursor, insert_query, values)\n",
    "    \n",
    "    conn.commit()\n",
    "    print(f\"Inserted {len(data_list)} records into {table_name}\")\n",
    "    cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1046d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data from API...\n",
      "Sample data item structure:\n",
      "{\n",
      "  \"idsensore\": \"12691\",\n",
      "  \"nometiposensore\": \"Arsenico\",\n",
      "  \"unitamisura\": \"ng/m\\u00b3\",\n",
      "  \"idstazione\": \"560\",\n",
      "  \"nomestazione\": \"Varese v.Copelli\",\n",
      "  \"quota\": \"383\",\n",
      "  \"provincia\": \"VA\",\n",
      "  \"comune\": \"Varese\",\n",
      "  \"storico\": \"N\",\n",
      "  \"datastart\": \"2008-04-01T00:00:00.000\",\n",
      "  \"utm_nord\": \"5073728\",\n",
      "  \"utm_est\": \"486035\",\n",
      "  \"lat\": \"45.81697450\",\n",
      "  \"lng\": \"8.82024911\",\n",
      "  \"location\": {\n",
      "    \"type\": \"Point\",\n",
      "    \"coordinates\": [\n",
      "      8.82024911,\n",
      "      45.8169745\n",
      "    ]\n",
      "  },\n",
      "  \":@computed_region_6hky_swhk\": \"1\",\n",
      "  \":@computed_region_ttgh_9sm5\": \"1\",\n",
      "  \":@computed_region_af5v_nc64\": \"3\"\n",
      "}\n",
      "Processing data...\n",
      "Connecting to PostgreSQL...\n",
      "Creating table if it doesn't exist...\n",
      "Inserting data into table...\n",
      "Inserted 984 records into sensors\n",
      "Process completed successfully!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# API URL\n",
    "api_url = \"https://www.dati.lombardia.it/resource/ib47-atvt.json\"\n",
    "\n",
    "# Define the table name for your data\n",
    "table_name = \"sensors\"\n",
    "\n",
    "try:\n",
    "    # Fetch data from API\n",
    "    print(\"Fetching data from API...\")\n",
    "    raw_data = fetch_data_from_api(api_url)\n",
    "    \n",
    "    # Debug: Inspect the data structure\n",
    "    print(\"Sample data item structure:\")\n",
    "    if raw_data:\n",
    "        print(json.dumps(raw_data[0], indent=2))\n",
    "    \n",
    "    # Process the data to handle nested structures and filter out problematic columns\n",
    "    print(\"Processing data...\")\n",
    "    processed_data = process_api_data(raw_data)\n",
    "    \n",
    "    # Connect to PostgreSQL\n",
    "    print(\"Connecting to PostgreSQL...\")\n",
    "    conn = connect_to_postgres()\n",
    "    \n",
    "    # Create table if it doesn't exist (using actual data to infer schema)\n",
    "    print(\"Creating table if it doesn't exist...\")\n",
    "    if processed_data:\n",
    "        create_table_if_not_exists(conn, table_name, processed_data[0])\n",
    "    \n",
    "    # Insert data into table\n",
    "    print(\"Inserting data into table...\")\n",
    "    insert_data(conn, table_name, processed_data)\n",
    "    \n",
    "    # Close connection\n",
    "    conn.close()\n",
    "    print(\"Process completed successfully!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf97e881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "se4g",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
